This is tl-manual.info, produced by Makeinfo version 3.12f from
tl-manual.texinfo.

   The manual and associated descriptions of ThinLisp, a Lisp-to-C
translator for real time applications and anything that shouldn't be
fat and slow.

   Copyright (c) 1999 The ThinLisp Group


File: tl-manual.info,  Node: Top,  Next: Preface,  Prev: (dir),  Up: (dir)

* Menu:

* Preface::                     What is ThinLisp?
* Acknowledgements::            Our Debts
* Rant::                        What Possessed Us to Make ThinLisp
* Original-Introduction::       Rant, circa 1995
* Memory::                      Type Tags, Memory Layout
* Index::                       Small, but growing.


File: tl-manual.info,  Node: Preface,  Next: Acknowledgements,  Prev: Top,  Up: Top

Preface
*******

   ThinLisp is an open source Lisp to C translator for delivering
commercial quality, Lisp-based application.  It implements a subset of
Common Lisp with extensions.  ThinLisp itself is written in Common
Lisp, and so must run on top of an underlying Common Lisp
implementation such as Allegro, MCL, or CMU Lisp.  The C code resulting
from a translation can then be independently compiled to produce a
small, efficient executable image.

   Originally designed for real-time control applications, ThinLisp is
not a traditional Lisp environment.  It purposefully does not contain a
garbage collector.  ThinLisp produces compile time warnings for uses of
inherently slow Lisp operations, for consing operations, and for code
that is unoptimizable due to a lack of sufficient type declarations.
These warnings can be suppressed by improving the code, or through use
of lexical declarations acknowledging that the code is only of
prototype quality.  Code meeting the stringent requirements imposed by
ThinLisp cannot by sped up by rewriting it in C.

   The ThinLisp home is <http://www.thinlisp.org/>.  The newest source
distributions of TL and this manual can be found here.  Bugs should be
reported to <bugs@thinlisp.org>.


File: tl-manual.info,  Node: Acknowledgements,  Next: Rant,  Prev: Preface,  Up: Top

Acknowledgements
****************

   ThinLisp was begun in 1995 as a late night project born of the
frustration of attempting to ship commercial quality software products
written in Lisp.  Four years later I'm still obsessed by the issues
that drove me to it in the first uplace -- practical use of high level
languages to implement complex applications while achieving the
performance that seems easy when using languages that are semantically
"close to the silicon".  Hopefully this implementation will lead to
some useful insights towards that goal.

   Thanks to Ben Hyde for convincing Gensym and myself that this system
should be taken off the shelf, polished up, and released as open source
software.  Mike Colena and Glen Iba wrote significant parts of the
implementation.  Nick Caruso, Joe Devlin, Rick Harris, and John
Hodgkinson and also contributed their time, sage opinions, and code.
Thanks to Lowell Hawkinson, Jim Pepe, and Dave Riddell for their
support of this work at Gensym Corporation.  Thanks to Kim Barrett and
David Sotkowitz of IS Robotics, Inc. for contributions of
multiple-inheritance code and opinions, and to Rod Brooks and Dave
Barrett for their ideas.  Finally, thanks to my wife, Gerry Zipser, for
putting up with the bleary-eyed aftermath of coding sessions, and for
helping to focus efforts during this past summer's release push.

Jim Allard
Newton, Massachusetts
October 6, 1999


File: tl-manual.info,  Node: Rant,  Next: Original-Introduction,  Prev: Acknowledgements,  Up: Top

Rant
****

My Excuse for Ranting
=====================

   I've imagined the reactions people will have when they see that
there is yet another Lisp to C translator implementation being
released.  Mostly I've expected that people would think I'm stark
raving mad to engage is a large work, to serve an almost non-existent
user base of programmers in a language that is largely discredited
while being actively antagonistic towards many of the design principles
this language has employed for decades.  Since I'm expecting that
people will think I'm mad (and half believing it myself), I then feel
entitled (even obligated) to engage in a rant to explain the
motivations of such a curious endeavor.  Please excuse this indulgence
and look charitably upon it as a form of self-therapy.

Lisp Background
===============

   More than fifteen years ago I was in a recitation session of an
Introduction to Artificial Inteligence course.  The lecturer, Patrick
Winston, had come in for a session on autyomated planning.  At one
point I asked a question about how a certain situation might be handled
in the system we were studying, and he answered that it couldn't be
handled in that system and that solving that problem was a research
topic.  The fact that problems as simple (so I thought at the time) as
what we were describing were research, and that as a sophomore in
college I could grasp them seemed amazing to me then, as it still does
now.  On the spot I could imagine six different ways to attack that
problem, and none of them felt any less plausable than some of the
established techniques that we were studying.  I was hooked.

   At the time, this sort of optimism and arrogance about the immediacy
and inevitablity of technical success in AI was rampant.  The
convergence of breakthroughs in techniques, tools, and venture capital
money that flowed like wine was intoxicating for everyone.

   No one thought this work would be trivial, so the best software
development tools available would be required.  And of course the best
tools from the perspective of the AI community included the language
that this community had been developing since the late 1950's, Lisp.

   Originally, Lisp was developed as an experiment in providing a
direct means of implementing lambda calculus, where operations were
first class objects that could be manipulated in the same manner as
data.  The presumption behind many of the Lisp design choices was that
the most important goal was to maximize a programmer's productivity in
developing new functionality by enabling the purest form possible of
coded solutions, and so to hide as many of the platform specific
details as possible.  In the ongoing evolution of Lips, considerations
of the efficiency of processing speed and memory use came in a distant
second to programmer convenience and to the attempt to protect the
programmer from bugs caused by mathematically abhorrant behaviors such
as integer wraparound.

   Perhaps because of this devotion to developer productivity; perhaps
because of the synergy between language syntax, parsing, and data;
perhaps because of the invention of the Lisp macro facility; or perhaps
because it was invented down the hall, Lisp became the language of
choice for research and experimentation in new programming constructs
(at least at MIT).  Many of the different possible approaches to object
oriented programming were first tried out in Lisp.  Examples are
multiple inheritance, multi-methods, prototype-based object sytems, and
automatic method combination via whoppers, wrappers, before, and after
methods.  Other innovations experimented with in Lisp are error handling
systems, multi-platform file naming approaches, and guaranteed
execution of clean-up code (i.e.  unwind-protect).

   In 1984 a group formed to attempt to unify as many of the best
features of different Lisp dialects as possible into one central
standard.  From this effort came the excellent books `Common Lisp, The
Language' by Guy Steele and it's second edition, which incorporated
many of the changes that would eventually be codified into ISO Common
Lisp.  This is the dialect that dominates Lisp work today, at least in
the U.S.

Mathematician's Languages
=========================

   From the beginning Lisp was a mathematian's language.  To understand
what I mean by Lisp this, I must explain my view of the differences
between the goals of scientists, mathematicians, and engineers.  (1)

   The goal of scientists is to learn truths about the world around
them, using observation, analysis, hypothesis, and experimentation to
advance and buttress their claims of discovery.  Pure science aspires
to being unconcerned with the utility or applicability of the
information they seek.  The ultimate goal is to discover what _is_.

   Mathematicians aspire to an even higher goal -- understanding what
truths there are or that might be, regardless of or even entirely
divorced from the limits of the physical world.  The studies of
mathematicians are the stuff of pure thought and imagination, yet bound
by the strictest of rules of proof.  To build robust castles in the air
based on proofs combining into a single monolithic whole requires that
all pieces must act perfectly in concert.  Therefore the mathematician
must constantly be vigilant against contradictions between the
different portions of his whole proof, where one technique carries with
it constraints which must be respected within all other parts of the
proof.  With this rigorous technique in hand, the ultimate goal is to
discover what is _true_.

   On the other hand the goal of the engineer, in the abstract, is to
bend the behavior of an uncooperative world to his will.  Whether it is
the stereotypical train engineer, civil engineer, accoustic,
electrical, mechanical, or software engineer, their work is to use the
fruits of science and mathematics, exploiting practicality and
expediency, to operate or design a physical entity so that it performs
a specific task, usually with the motivation of the almighty dollar.
Within the constraints of the physical world, the ultimate goal is to
accomplish what is _practical_.

   Most computer langauges is use today are exemplars of the
engineering style.  Building primarily from the operations that could
be implemented on the computing devices that could be made at the time,
and perhaps secondarily on the needs of a user base at hand, languages
were designed to allow people to command computers to do things.
Typically the operations in the language were semanticly thin (or
shallow, if you prefer), to the extent that a programmer of medium
experience could almost predict the number of machine instructions
required to carry out any given command in the language.  Fortran,
Pascal, Basic, and C are all examples of languages in this category,
with C (and it's derivative, C++) now being the default choice for
people building big systems.

   Lisp and other Languages (such as Smalltalk, Eiffel, and recently
Java) were developed along along a different tack.  The operations in
these languages were defined with deep semantics in mind.  Here the
focus was not on what an operation _did_ but on what it _meant_.  Of
course there had to be implementations of these operations, but the
actual machine instructions carried out were allowed (even expected) to
vary widely depending on the manner and situation in which it was used.

   An example of how this difference in design perspective plays out
can be found in the behavior of the `goto' statement in C and the `go'
special operator in Common Lisp.  Consider the following two code
fragments.

   In C:

     int find_big_int(int *set, int start, int end) {
       Iterate through the set {
         if test
           goto bad;
           ...
       }
      bad:
       ...
     }

   In Lisp:

     (defun find-big-int (set start end)
       (tagbody
         (Iterate through the set
           (if test
             (go bad))
           ...)
         bad
         ...))

   Describe why a lexical closure surrounding the `(go bad)' could make
this very expensive. (2)

Lisp in Action
==============

   In any case, the bulk of the research labs and companies that
attempted to commercialize AI technologies used Common Lisp to
implement their products.  The most broadly deployed AI-based technique
was expert systems, also called rule-based systems.  (3)  Early results
were encouraging.  In the lab, sometimes on specialized hardware, the
software engineers were able to demonstrate the beginnings of the
functionality that they were promising.  However, when it came to
deploying these systems, things didn't turn out so smoothly.  Most
software products of that era were coded in languages such as Fortran,
Cobol, Pascal, C, and a assembly language.  It turned out that Software
developers who could breathe fire in Lisp were clumsy, inefficient, or
flatly unwilling to port their systems to these traditional languages.

   which were used at the time to deliver the majority of commercial
products

   Customers were loathe to buy expensive, special purpose hardware for
these applications while cheap, ever more powerful PC computers were
rolling out.  Stories of this sort are rife thoughout the industry, but
I'll speak to just the cases I personnally was involvded in.

   ---------- Footnotes ----------

   (1) All apologies in advance to my father-in-law (a scientist) and
my brother-in-law (a mathematician).

   (2) This needs further work.  Describe Godelizing, the tendency of
"mathematical" programmers to choose such correct, but overweight
implementation approaches, and the underestimation by the abstract
minded of the difficulty of abstracts to the teams of people needed to
finish a complex software system.

   (3) Of course this is ignoring other, more broadly applicable
developments, such as multi-tasking operating systems.


File: tl-manual.info,  Node: Original-Introduction,  Next: Memory,  Prev: Rant,  Up: Top

Original Introduction
*********************

   _This introduction was written at the beginning of the effort to
make a new Lisp to C translator.  At the time I was working for Gensym
Corporation, and named the project after the company.  -jallard 10/9/99_

   The Gensym Language Translator (GLT) is being made to enable Gensym
to control the means of distribution of its products.  Since 1986 till
now (January, 1995), we have used 6 different brands of Lisp compiler,
abandoning each one in turn for platform availability, portability, and
performance reasons.  Most recently we have been using the Chestnut
Lisp to C translator to deliver our Lisp-based products for releases 3
and 4.  Between these two releases of our products, we took a new
release from Chestnut, and it took a full man-year of my time to
resolve the problems that had been introduced.  I've made the judgment
that for less labor than is devoted to maintaining our use of
Chestnut's product, we can implement and maintain our own translator.
It's my intent to implement a translator that meets or beats Chestnut's
characteristics for the portions of Lisp that we use, and that does not
waste time or attention on the portions that we do not use.  Time can
be taken later to extend it into areas we would like to use, but
currently cannot because we can't depend on non-consing implementations.

   The base of GLT consists of a small hand-written C include file, a
small hand-written memory allocation C file, and a translator written
in Common Lisp that can translate a minimal set of primitives from Lisp
to C.  The primitives in the translator implement data structure
allocation and manipulation, the defining of constants, parameters,
variables, macros, and functions.  The system will not contain many of
the features normally present in a full Common Lisp implementation,
most notably no garbage collector, lexical closures, rest arguments,
condition system, bignums, complex numbers, or CLOS.  (1)  The built-in
types will be limited to packages, symbols, conses, fixnums, doubles,
simple-vectors, simple- arrays of unsigned-byte 1, 8, and 16 bits,
simple-arrays of doubles, and fill-pointered non-adjustable strings.
Notable complex features that will be included are special variables,
catch and throw, unwind-protect, multiple-values, optional arguments,
defstruct, macrolet, labels, flet, and deftype.

   Particular attention will be paid to using C integer and double
types for variables, function arguments, and function values when type
declarations allow, largely because it bugs me when these things aren't
handled right and I believe it is a significant performance loss to
always be boxing and unboxing at function boundaries.  We will also
make special efforts to optimize calls to functions that return a
single value.

   ---------- Footnotes ----------

   (1) Rest arguments have since been added.  -jallard 10/9/99.


File: tl-manual.info,  Node: Memory,  Next: Index,  Prev: Original-Introduction,  Up: Top

Memory Architecture
*******************

   Use pointers to a one word (4 byte) header structure as the basic
mechanism.  The type should be an 8-bit unsigned byte value.  The upper
3 bytes of the header word should be used for type specific data.  For
vectors this should be the length, giving us a simple vector with one
word of overhead (all previous Lisp implementations we've used, except
the Lispm, had two or more words of header).  All Lisp objects should
be aligned on 4 byte addresses.  There is an argument that they should
be aligned on 8 byte addresses.  There are two advantages to 8 byte
alignment.  One is that it would enable us to reliably store immediate
double floats and pointers into the same array.  The second is that it
would can give us an immediate type tag for conses that is itself the
offset to the cdr of a cons.  The argument for 4 byte alignment is that
all current C compilers we use align structures on 4 byte addresses,
but some won't align them on 8 byte addresses, even if they contain
doubles.  The other argument for 4 byte alignment is that we would not
need to occasionally skip forward 4 bytes when allocating from heap in
order to find the next 8 byte aligned address.  For now, the 4 byte
alignment wins.

   The exceptions to the pointer to a type tag rule are the following
types, which have immediate type tags.  These types are fixnums,
conses, and managed-floats.  If all pointers are 4 byte aligned, then
the lower 2 bits of all pointers are always zeros.  This gives us 3
non-zero immediate type tags.  The following are the immediate type tag
assignments:

       0:  pointer to header of Lisp object
       1:  immediate fixnum
       2:  pointer to cons (mask with -4 for car*, follow for cdr*)
       3:  immediate character

   A determination of type can be made from a hex value of the pointer.

       hex 0, 4, 8, C are pointers to Lisp objects
       hex 1, 5, 9, and D are fixnums,
       hex 2, 6, A, and E are pointers to conses
       hex 3, 7, B, and F are immediate characters.

   The arguments for a 30 bit fixnum instead of a 31 is that it makes
for fast fixnum additions and subtractions without risking overflow.
31 bit fixnums require a sequence point between operations to avoid the
potential for overflow.

   Characters could be either immediate or remote, though there is some
performance benefit to characters being immediate.  We could have a
preallocated array of remote character objects, and allocate a Lisp
character is arefing into this array.  For now we are going with
immediate characters, especially since we are thinking hard about
UNICODE characters, which require 16 bits and so make a pre-allocated
array become somewhat too large.

   The type tags in headers should not conflict with any of the
immediate type tags, so that type-case can turn into a fixnum-case of
the type values.

   Given these set ups, type tests against straight types are at worst
a null test, a mask and an integer equality test, a character byte
fetch, and another integer equality test.

   In C, the type for object should be an unsigned integer type 32 bits
long.  There are several advantages to this.  All architectures
(including the Alpha OSF when using a linker option) can have pointer
values be represented in 32 bits, but for some platforms (the Alpha
OSF) pointer types can consume something other that 4 bytes, 8 for all
pointers on the Alpha OSF.  By forcing all objects to consume 4 bytes,
we can get interesting packing in structures and vectors on all
platforms.  [The following comment applies only to 8 byte alignment: For
example, we could put immediate floats into odd-indexed simple vector
locations, and those floats would consume 2 elements.  For structures
and frames, this could provide significant savings.  -jra 8/30/95]

   The type for managed float should have an immediate type tag so that
we may have the smallest possible representation for floats, since so
many are used.  For each type that involves a heap allocated block of
memory (i.e. all but fixnum and characters), there should be a
corresponding type for a reclaimed instance of that type.  This gives
us a fast means of testing if a data structure is currently reclaimed
or not, and would cause type tests in a safe translation.  Even in
production systems, we could check for double reclamation of data
structures.  Note that this is not possible for heap allocated data
structures that use an immediate type tag.

   The type tags for heap allocated data structures have no special
issues, except that these values should not collide with any immediate
type tags (i.e. be greater than 3), and be able to quickly determine if
a data structure is reclaimed (i.e. use bit 7 as a flag).

   So the type tag table is as follows:

     Tag Value							Reclaimed Tag
     Dec     Hex	Lisp Type		C Type & Conv		Dec    Hex
     -------------	---------		-------------		-------------
     0	00	immed pointer		(Header *)Obj
     1	01	immed fixnum		((sint32)Obj)>>2
     2	02	cons			(Obj *)(Obj-2)
     3	03	immed character		(unsigned char)(Obj>>2)
     4	04	managed-float		(Mdouble *)Obj		132	84
     5	05	double-float		(Ldouble *)Obj		133	85
     6	06	simple-vector		(Sv *)Obj	 	134	86
     7	07	string (w/fill ptr)	(Str *)Obj	 	135	87
     8	08	(simple-array ubyte 8)	(Sa_uint8 *)Obj	 	136	88
     9	09	(simple-array ubyte 16)	(Sa_uint16 *)Obj 	137	89
     10	0A	(simple-array double)	(Sa_double *)Obj 	138	8A
     11	0B	symbol			(Sym *)Obj	 	139	8B
     12	0C	compiled-function	(Func *)Obj	 	140	8C
     13	0D	package			(Package *)Obj	 	141	8D

   Each of the data structures are described below.

Simple-vectors
==============

   Simple vectors are the most often used data structure, so we'd like
to keep it as small and fast as possible.  It has a one word (i.e. 4
byte) header.  The only components of a simple vector are the type tag,
the length, and the body of the array.  If the type tag is 8 bits wide
(unsigned) then the length can be 24 bits of unsigned integer, giving a
maximum length of 16 Meg.

     typedef struct {
       unsigned int:8:type;
       unsigned int:24:length;
       Obj[1]:body;
     } Sv

   In C references to array are guaranteed to not be bounds clicked.
this means that this one type can be used to all elements of
arbitrarily sized simple vectors.  Constant vectors can be made by
having a type of simple-vector local to the C file containing the
constant so that we can use an initialized structure.  For example, a
constant simple vector containing 5 fixnums could be emitted as C code
as follows.

     typedef struct {
       unsigned int:8:type;
       unsigned int:24:length;
       Obj[5]:body;
     } Sv_5
     
     static Sa_5 const1 = {8, 5, {fix(23), fix(2), fix(3),
       fix(9), fix(-12)}};

   An example of the translation of a fetch of a simple vector element
follows.

       Lisp: (setq x (svref y 5))
       C:    x = (Sv *)y->body[5];

   Though the detail of casting and fetching the body component could
be hidden in a C macro, at first we will leave all the details exploded
out.  One criticism of Chestnut's translations is that no one can
figure out what the implementation is actually doing.  Exploding out
the details will help train development in the details.

Strings
=======

   In order to give fast performance for all strings, we will have fill
pointers for all strings in G2.  The fill pointer and length will both
consume 3 bytes, plus one byte for the tag.  The body of the string
will be packed directly against the fill pointer, meaning that the most
efficient packing of strings into our 8 byte aligned space will be for
strings with lengths that have mod (length, 8)=1.  Since strings in C
must be null terminated, that adds 1 extra byte to the length as
compared to the loop length of the string.  Having 1 extra byte in the
header word will allow us to efficiently pack strings into words when
they have lengths that are multiples of 4.

     typedef struct {
       unsigned int: 8: type;
       unsigned int:24: length;
       unsigned int:24:fill_length;
       char[9]: body
     } Str

Immediate integer and double arrays
===================================

   All of these types are implemented in the same way, with a 4
byte-aligned one byte type tag, a 3 byte length, and then a body.
These types are Sa_uint8 and Sa_uint16.  Sa_double is similar except
that it is 8 byte aligned..  The type for bit-vectors is built on top
of Sa_uint8, by fetching bytes and bit-shifting to fetch values and
modify values.

Symbol
======

   There are several different optimizations that one can imagine for
the slots of symbols.  In the first pass of this implementation, no
such memory squeezing will be attempted, and all five typical slots of
symbols will be directly provided in the symbol structure.  Also, since
virtually all symbols are included in packages in G2 and TW, the slots
needed for holding the symbol in package balanced binary trees will be
included in the symbol itself.

     typedef struct {
       unsigned int:8:type;
       unsigned int:1:local_value;
       unsigned int:1:external;
       signed int:4:balance;
       unsigned int:1:imported;
       unsigned int:16:name_hash;
       Obj:symbol_name;
       Obj:symbol_value;
       Obj:symbol_plist;
       Obj:symbol_package;
       Obj:symbol_function;
       Obj:package_left_branch;
       Obj:package_right_branch;
     } Symbol

   The symbol-value slot is typically a pointer to the location
containing the true symbol value, which will typically be a C global
variable.  When a runtime generated symbol has a value, the local-value
bit will be 1, and the value is directly within the symbol-value slot.
Note that slows down explicit calls to Lisp symbol-value since it has
to check the local_value bit, but these explicit calls are rare and so
I don't think that's so bad.

   If packages are implemented as balanced binary trees, using the hash
value of the name as an index, then there can be collisions between
these hash values.  In this case, the symbol names will be
alphabetically ordered to determine left, right or match.  These
choices give us a constant size for symbols, given the size of the
symbol-name.

Compiled Functions
==================

   Compiled functions will contain a pointer to the C function for this
compiled function, the number of arguments for the function; the number
of those arguments that are optional in the Lisp function, and a list
of the constants that are default values for the optional arguments.
Within the C runtime system, all functions will receive all arguments.
If a funcall of a compiled function occurs where some optional
arguments are not provided, the default values are extracted from the
list of default values.  (In circumstances where the default value
semantics require more than a constant, the no-arg argument value will
be passed, and further computation will happen within the function to
implement the default value selection).

     typedef struct {
       unsigned int:8:type;
       unsigned int:8:arg_count;
       unsigned int:8:optional_arguments;
       Obj:default_arguments;
       void *f(): c_function;
     } Func

   The type spec for compiled functions will typically have arguments
of type Obj: and a return type Obj: In special cases we may provide
unsafe optimizations for functions that do not have object type arg and
return values, but these should never be given to the default funcall
operations.

Characters
==========

   Since all immediate type tags are in use, we will use heap allocated
character objects.  To avoid the need to reclaim them, we will
preallocate all 256 character objects (at 8 bytes per, that's 2K).  The
value is explicitly unsigned to avoid confusion in parts that have a
default signed char type.

     typedef struct {
       double [0]: align;
       unsigned int:8:type;
       unsigned char:value
     } Lchar

Package
=======

   Packages are implemented as balanced binary trees.  They contain a
list of used packages, and a symbol (or null pointer) that is the root
node of the balanced binary tree.  The balanced binary tree of symbol
structures will hold only symbols that are local to this package and
that have been imported to this package.  External symbols of a package
are represented by mask bits on the symbol itself.  Imported symbols
are represented by a new symbol structure in the binary tree, and its
symbol value points to the imported symbol.  The intern function will
be implemented by searching through the binary trees of this package
then through the binary trees of used packages and their used packages,
but only accepting external symbols.

     typedef struct {
       unsigned int:8:type;
       Obj:root_symbol;
       Obj:used_package_list;
     } Pkg

Obsolete 8 Byte Alignments
==========================

   [The following section describes tagging for 8 byte alignments.
Keeping for historical perspective.  -jra 8/30/95]

   The exceptions to the pointer to a type tag rule are the following
types, which have immediate type tags.  These types are fixnums,
characters, managed-floats, and conses.  If all pointers are 8 byte
aligned, then the lower 3 bits of all pointers are always zeros.  This
gives us 7 non-zero immediate type tags.  The following are the
immediate type tag assignments:

       0:  pointer to header of Lisp object
       1:  immediate even fixnum
       2:  immediate character
       3:  pointer to managed-float (mask with -8 for double*)
       4:  pointer to cons (mask with -8 for car*, follow for cdr*)
       5:  immediate odd fixnum
       6:  pointer to double-float (mask with -8 for double*)
       7:  unused

   With this implementation, some determination of type can be made
from the printed hex value of the pointer:

       hex 0 and 8 are pointers to Lisp objects,
       hex 1, 5, 9, and D are fixnums,
       hex 2 and A are characters,
       hex 3 and B are managed-floats,
       hex 4 and C are conses,
       hex 6 and E are double-floats,
       hex 7 and F are unused, so must be corrupted objects

   By having a cons tag of 4 and a headerless cons, the access to one
of the elements of the cons will be a straight pointer dereference.
The other requires subtracting 4 from the pointer first.  (On the Alpha
OSF or other 8 byte pointer, machines, some address computation is
necessary for both the car and cdr, unless we make object a 4 byte wide
data type, which we could do).

   The type tags for heap allocated data structures have no special
issues, except that these values should not collide with any immediate
type tags (i.e. be greater than 7), and be able to quickly determine if
a data structure is reclaimed (i.e. use bit 7 as a flag).

   So the type tag table is as follows:

       Tag	(Hex)	Lisp Type		C Type		 Reclaimed Tag
       -------------	---------		------		 -------------
       0	00	immed pointer		(Header *)Obj
       1	01	immed even fixnum	(sint32)Obj>>2
       2	02	immed character		(char)(Obj>>2)
       3	03	managed-float		(double *)Obj
       4	04	cons			(Obj *)Obj-1
       5	05	immed odd fixnum	(sint32)Obj>>2
       6	06	double-float		(double *)Obj
       7	07	unused
       8	08	simple-vector		(Sv *)Obj	 136	88
       9	09	string (w/fill ptr)	(Str *)Obj	 137	89
       10	0A	(simple-array ubyte 8)	(Sa_uint8 *)Obj	 138	8A
       11	0B	(simple-array ubyte 16)	(Sa_uint16 *)Obj 139	8B
       12	0C	(simple-array double)	(Sa_double *)Obj 140	8C
       13	0D	symbol			(Sym *)Obj	 141	8D
       14	0E	compiled-function	(Func *)Obj	 142	8E
       15	0F	package			(Package *)Obj	 143	8F

   Note the use of a zero length double array at the beginning of the
struct.  This ensures double word alignment, which gives us two things.
The first is that pointers to constant structures of this type will be
on 8 byte boundaries, required for our use of 3 bits of immediate type
tag.  The second benefit is that with a known alignment we can reliably
mix objects and immediate doubles in simple-vectors.  This is needed
for structure and frame extensions I would like to make.  The Harbison
and Steele manual suggests that this zero length double array technique
will ensure alignment, but this has not yet been tested.


File: tl-manual.info,  Node: Index,  Prev: Memory,  Up: Top

Index
*****

* Menu:

* rant:                                  Rant.



Tag Table:
Node: Top277
Node: Preface682
Node: Acknowledgements2008
Node: Rant3514
Node: Original-Introduction13523
Node: Memory16532
Node: Index32894

End Tag Table
